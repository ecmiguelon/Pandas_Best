{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0105abc-6923-484e-bb0b-a4e3542df58e",
   "metadata": {},
   "source": [
    "# Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b7b5a-e770-454b-9487-0b2a9b8a7ddd",
   "metadata": {},
   "source": [
    "Pandas has multiple possible underlying type systems. There are the classic NumPy types, but also the new PyArrow types. These can coexist in the same data frame, but seemingly similar types can have different properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665b2ff4-1ec5-4184-b543-3d4f2bc557f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([1.0, 2.0, 3.0], dtype=\"float64\")\n",
    "s2 = pd.Series([0.3, 1.3, 2.7], dtype=\"float64[pyarrow]\")\n",
    "\n",
    "df = pd.DataFrame({\"first\": s1, \"second\": s2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e0507b-fdfe-4ae1-95b7-28e56d7671a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype          \n",
      "---  ------  --------------  -----          \n",
      " 0   first   3 non-null      float64        \n",
      " 1   second  3 non-null      double[pyarrow]\n",
      "dtypes: double[pyarrow](1), float64(1)\n",
      "memory usage: 180.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd5d38-bb94-4520-b457-6dfa3f1bac3e",
   "metadata": {},
   "source": [
    "Properties of NumPy types:\n",
    "- Automatic type conversion to Python `int` when dealing with large integers\n",
    "- Automatic type conversion to `float64` when `NaN` values appear\n",
    "- Conversion to \"smaller\" types is possible; overflows will happen without warning\n",
    "- NumPy doesn't have a string type; strings are treated as general `object`s\n",
    "\n",
    "Properties of PyArrow types:\n",
    "- No automatic type conversions for large integers; an error is thrown instead\n",
    "- No automatic overflows will happen when converting to smaller types; an error is thrown if one would occur\n",
    "- Integer types can handle `<NA>` values\n",
    "- No direct conversion from strings to floating point types; you must go through NumPy\n",
    "- PyArrow does have a dedicated string type, but you need to create it with `pd.ArrowDtype(pa.string())`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a733efc-f5a6-43c1-bc6f-d7e63f004da0",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fe21f-6ccc-48c1-a42b-6586920e206a",
   "metadata": {},
   "source": [
    "Use the `category` type for categorical data with a *low* number of categories. If there are too many categories, this becomes less efficient than treating the values as strings. PyArrow has a `dictionary` type for this kind of data, but the author ignores it in favor of the Pandas 1.x `category` type. `dictionary` is not exposed directly in Pandas unlike other PyArrow data types.\n",
    "\n",
    "Pandas also supports ordered categories in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e48e0a-f7b0-48e7-8bf0-2f87b91c4828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    CA\n",
       "1    NY\n",
       "2    TX\n",
       "dtype: category\n",
       "Categories (3, object): ['CA', 'NY', 'TX']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = ['CA', 'NY', 'TX']\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "pd.Series(states, dtype='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd7bfd1-0151-4e8a-98ec-6dde903d52bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan\n",
       "1     Feb\n",
       "2     Mar\n",
       "3     Apr\n",
       "4     May\n",
       "5     Jun\n",
       "6     Jul\n",
       "7     Aug\n",
       "8     Sep\n",
       "9     Oct\n",
       "10    Nov\n",
       "11    Dec\n",
       "dtype: category\n",
       "Categories (12, object): ['Jan' < 'Feb' < 'Mar' < 'Apr' ... 'Sep' < 'Oct' < 'Nov' < 'Dec']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_cat = pd.CategoricalDtype(categories=months, ordered=True)\n",
    "pd.Series(months, dtype=month_cat).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0dabf55-bea6-4cf9-a3c8-a3004eb8ace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan\n",
       "1     Feb\n",
       "2     Mar\n",
       "3     Apr\n",
       "4     May\n",
       "5     Jun\n",
       "6     Jul\n",
       "7     Aug\n",
       "8     Sep\n",
       "9     Oct\n",
       "10    Nov\n",
       "11    Dec\n",
       "dtype: category\n",
       "Categories (12, object): ['Jan' < 'Feb' < 'Mar' < 'Apr' ... 'Sep' < 'Oct' < 'Nov' < 'Dec']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "string_pa = pd.ArrowDtype(pa.string())\n",
    "pd.Series(months, dtype=string_pa).astype(month_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca35f164-2a8f-44d7-9c8d-8a7b0da7f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan\n",
       "1     Feb\n",
       "2     Mar\n",
       "3     Apr\n",
       "4     May\n",
       "5     Jun\n",
       "6     Jul\n",
       "7     Aug\n",
       "8     Sep\n",
       "9     Oct\n",
       "10    Nov\n",
       "11    Dec\n",
       "dtype: category\n",
       "Categories (12, string[pyarrow]): [Jan < Feb < Mar < Apr ... Sep < Oct < Nov < Dec]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not included in book, but this is how to use the 1.x categorical type with an\n",
    "# underlying 2.x PyArrow data type.\n",
    "month_cat = pd.CategoricalDtype(categories=pd.Series(months, dtype=string_pa), ordered=True)\n",
    "pd.Series(months, dtype=string_pa).astype(month_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db2768-fd9c-4609-808b-e9453fe31e09",
   "metadata": {},
   "source": [
    "## Dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4405f577-234c-4533-a5ff-c0826acf3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "dt_list = [dt.datetime(2020, 1, 1, 4, 30), dt.datetime(2020, 1, 2), dt.datetime(2020, 1, 3)]\n",
    "string_dates = ['2020-01-01 04:30:00', '2020-01-02 00:00:00', '2020-01-03 00:00:00']\n",
    "string_dates_missing = ['2020-01-01 4:30', None, '2020-01-03']\n",
    "epoch_dates = [1577836800, 1577923200, 1578009600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765e987d-6bc0-45a0-a9dc-43eef1898961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01 04:30:00\n",
       "1   2020-01-02 00:00:00\n",
       "2   2020-01-03 00:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2809287-cd09-4ca4-8d12-a596e0c0e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01 04:30:00\n",
       "1   2020-01-02 00:00:00\n",
       "2   2020-01-03 00:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string_dates, dtype='datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77db0fa5-724d-4297-b395-fa4c81fc7411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01 04:30:00\n",
       "1                   NaT\n",
       "2   2020-01-03 00:00:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string_dates_missing, dtype='datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b06b5-1887-4276-9fab-dda2678d0168",
   "metadata": {},
   "source": [
    "Be careful with epoch times; make sure you know the units. Here, the times are in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45365102-521d-4517-8b45-a61a5bcb3553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-01-01\n",
       "1   2020-01-02\n",
       "2   2020-01-03\n",
       "dtype: datetime64[s]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(epoch_dates, dtype='datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9ff589-cf4d-44df-b8a2-0c127e67edfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 04:30:00\n",
       "1    2020-01-02 00:00:00\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[ns][pyarrow]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dt_list, dtype='timestamp[ns][pyarrow]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05656a5-fe94-4a3b-a699-a3b47a9ffa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 04:30:00\n",
       "1    2020-01-02 00:00:00\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[ns][pyarrow]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(string_dates, dtype='timestamp[ns][pyarrow]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ccf1f-241a-4ca5-b7f9-4799b7da92d2",
   "metadata": {},
   "source": [
    "Missing data seems to fail with PyArrow times:\n",
    "\n",
    "`pd.Series(string_dates_missing, dtype='timestamp[ns][pyarrow]')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e65c62-ef46-4986-ae16-61d933888ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-01-01 00:00:00\n",
       "1    2020-01-02 00:00:00\n",
       "2    2020-01-03 00:00:00\n",
       "dtype: timestamp[s][pyarrow]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(epoch_dates, dtype='timestamp[s][pyarrow]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669414b-fab6-437c-bbaa-9d35cf86078b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16a449-cb92-48f7-8279-347e1bb69512",
   "metadata": {},
   "source": [
    "1. To represent the number of people in the US, I would use the `uint32[pyarrow]` type, which has a maximum value of around 4 billion. For the number of people worldwide, I would use the `uint64[pyarrow]` type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec70196-6d81-4395-a886-111e43e93b33",
   "metadata": {},
   "source": [
    "2. To describe a product, I would likely use the `category` type. For the name, I would use a PyArrow string. For the price, I might use a floating-point value like `float32[pyarrow]`, but PyArrow provides exact decimals in `pa.decimal128`, so I might consider that for its precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a25f0-808d-4c4b-909b-142f6d519e6f",
   "metadata": {},
   "source": [
    "3. For the date and time of a stock trade, I would use the `timestamp[ns][pyarrow]` type. For a date of birth of a person, I would likely use the `pa.date32` type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
